{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:45: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/keras/legacy/layers.py:460: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:47: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38951745"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy.random as rng\n",
    "import numpy as np\n",
    "import os\n",
    "import dill as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def W_init(shape,name=None):\n",
    "    \"\"\"Initialize weights as in paper\"\"\"\n",
    "    values = rng.normal(loc=0,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "#//TODO: figure out how to initialize layer biases in keras.\n",
    "def b_init(shape,name=None):\n",
    "    \"\"\"Initialize bias as in paper\"\"\"\n",
    "    values=rng.normal(loc=0.5,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "\n",
    "input_shape = (105, 105, 1)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "#build convnet to use in each siamese 'leg'\n",
    "convnet = Sequential()\n",
    "convnet.add(Conv2D(64,(10,10),activation='relu',input_shape=input_shape,\n",
    "                   kernel_initializer=W_init,kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(7,7),activation='relu',\n",
    "                   kernel_regularizer=l2(2e-4),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(4,4),activation='relu',kernel_initializer=W_init,kernel_regularizer=l2(2e-4),bias_initializer=b_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(256,(4,4),activation='relu',kernel_initializer=W_init,kernel_regularizer=l2(2e-4),bias_initializer=b_init))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(4096,activation=\"sigmoid\",kernel_regularizer=l2(1e-3),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "#encode each of the two inputs into a vector with the convnet\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "#merge two encoded inputs with the l1 distance between them\n",
    "L1_distance = lambda x: K.abs(x[0]-x[1])\n",
    "both = merge([encoded_l,encoded_r], mode = L1_distance, output_shape=lambda x: x[0])\n",
    "prediction = Dense(1,activation='sigmoid',bias_initializer=b_init)(both)\n",
    "siamese_net = Model(input=[left_input,right_input],output=prediction)\n",
    "#optimizer = SGD(0.0004,momentum=0.6,nesterov=True,decay=0.0003)\n",
    "\n",
    "optimizer = Adam(0.00006)\n",
    "#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\n",
    "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer)\n",
    "\n",
    "siamese_net.count_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "The data is pickled as an N_classes x n_examples x width x height array, and there is an accompanyng dictionary to specify which indexes belong to which languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training alphabets\n",
      "['Alphabet_of_the_Magi', 'Cyrillic', 'Gujarati', 'Japanese_(katakana)', 'Sanskrit', 'Japanese_(hiragana)', 'Korean', 'Mkhedruli_(Georgian)', 'Ojibwe_(Canadian_Aboriginal_Syllabics)', 'Latin', 'Early_Aramaic', 'Grantha', 'Asomtavruli_(Georgian)', 'Futurama', 'Bengali', 'Armenian', 'Anglo-Saxon_Futhorc', 'Tifinagh', 'Balinese', 'Braille', 'Greek', 'Tagalog', 'N_Ko', 'Blackfoot_(Canadian_Aboriginal_Syllabics)', 'Arcadian', 'Malay_(Jawi_-_Arabic)', 'Inuktitut_(Canadian_Aboriginal_Syllabics)', 'Burmese_(Myanmar)', 'Hebrew', 'Syriac_(Estrangelo)']\n",
      "validation alphabets:\n",
      "['Atemayar_Qelisayer', 'ULOG', 'Sylheti', 'Angelic', 'Glagolitic', 'Aurek-Besh', 'Oriya', 'Avesta', 'Kannada', 'Tengwar', 'Keble', 'Mongolian', 'Gurmukhi', 'Ge_ez', 'Malayalam', 'Atlantean', 'Old_Church_Slavonic_(Cyrillic)', 'Tibetan', 'Syriac_(Serto)', 'Manipuri']\n"
     ]
    }
   ],
   "source": [
    "with open( \"/home/soren/keras-oneshot/train.pickle\",\"r\") as f:\n",
    "    (X,c) = pickle.load(f)\n",
    "\n",
    "with open( \"/home/soren/keras-oneshot/val.pickle\",\"r\") as f:\n",
    "    (Xval,cval) = pickle.load(f)\n",
    "    \n",
    "print(\"training alphabets\")\n",
    "print(c.keys())\n",
    "print(\"validation alphabets:\")\n",
    "print(cval.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Siamese_Loader:\n",
    "    \"\"\"For loading batches and testing tasks to a siamese net\"\"\"\n",
    "    def __init__(self, path):\n",
    "        self.data = {}\n",
    "        self.categories = {}\n",
    "        self.info = {}\n",
    "        with open(os.path.join(path,\"train.pickle\"),\"r\") as f:\n",
    "            (X,c) = pickle.load(f)\n",
    "            self.data[\"train\"] = X\n",
    "            self.categories[\"train\"] = c\n",
    "        with open(os.path.join(path,\"val.pickle\"),\"r\") as f:\n",
    "            (X,c) = pickle.load(f)\n",
    "            self.data[\"val\"] = X\n",
    "            self.categories[\"val\"] = c\n",
    "            \n",
    "        self.n_classes,self.n_examples,self.w,self.h = self.data[\"train\"].shape\n",
    "        self.n_val,self.n_ex_val,_,_ = self.data['val'].shape\n",
    "\n",
    "    def get_batch(self,n,s=\"train\"):\n",
    "        \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
    "        X=self.data[s]\n",
    "        categories = rng.choice(self.n_classes,size=(n,),replace=False)\n",
    "        pairs=[np.zeros((n, self.h, self.w,1)) for i in range(2)]\n",
    "        targets=np.zeros((n,))\n",
    "        targets[n//2:] = 1\n",
    "        for i in range(n):\n",
    "            category = categories[i]\n",
    "            idx_1 = rng.randint(0,self.n_examples)\n",
    "            pairs[0][i,:,:,:] = X[category,idx_1].reshape(self.w,self.h,1)\n",
    "            idx_2 = rng.randint(0,self.n_examples)\n",
    "            #pick images of same class for 1st half, different for 2nd\n",
    "            category_2 = category if i >= n//2 else (category + rng.randint(1,self.n_classes)) % self.n_classes\n",
    "            pairs[1][i,:,:,:] = X[category_2,idx_2].reshape(self.w,self.h,1)\n",
    "        return pairs, targets\n",
    "    \n",
    "\n",
    "    def make_oneshot_task(self,N,s=\"val\",language=None):\n",
    "        \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
    "        X=self.data[s]\n",
    "        n_classes, n_examples = X.shape[0],X.shape[1]\n",
    "        if language is not None:\n",
    "            low, high = self.categories[s][language]\n",
    "            if N > high - low:\n",
    "                raise ValueError(\"This language ({}) has less than {} letters\".format(language, N))\n",
    "            categories = rng.choice(range(low,high),size=(N,),replace=False)\n",
    "            indices = rng.randint(0,self.n_examples,size=(N,))\n",
    "            \n",
    "        else:#if no language specified just pick a bunch of random letters\n",
    "            categories = rng.choice(range(n_classes),size=(N,),replace=False)            \n",
    "        true_category = categories[0]\n",
    "        ex1, ex2 = rng.choice(n_examples,replace=False,size=(2,))\n",
    "        test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N,self.w,self.h,1)\n",
    "        support_set = X[categories,indices,:,:]\n",
    "        support_set[0,:,:] = X[true_category,ex2]\n",
    "        support_set = support_set.reshape(N,self.w,self.h,1)\n",
    "        targets = np.zeros((N,))\n",
    "        targets[0] = 1\n",
    "        targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "        pairs = [test_image,support_set]\n",
    "\n",
    "        return pairs, targets\n",
    "    \n",
    "    def test_oneshot(self,model,N,k,s=\"val\",verbose=0):\n",
    "        \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "        n_correct = 0\n",
    "        if verbose:\n",
    "            print(\"Evaluating model on {} unique {} way one-shot learning tasks ...\".format(k,N))\n",
    "        for i in range(k):\n",
    "            inputs, targets = self.make_oneshot_task(N,s)\n",
    "            probs = model.predict(inputs)\n",
    "            if np.argmax(probs) == np.argmax(targets):\n",
    "                n_correct+=1\n",
    "        percent_correct = (100.0*n_correct / k)\n",
    "        if verbose:\n",
    "            print(\"Got an average of {}% {} way one-shot learning accuracy\".format(percent_correct,N))\n",
    "        return percent_correct\n",
    "\n",
    "loader = Siamese_Loader(\"/home/soren/keras-oneshot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHgAAADuCAYAAADyW8OMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABypJREFUeJztnUuS5SYQRcHhJbwet/ZQ3v8K6i2ixq494ImJUiv0ISET\nZV7dM3E4Wg+BDqQAAZVLKYng8tfdGSC2UDA4FAwOBYNDweBQMDgUDA4Fg0PB4Pwtufj1epVlWYyy\nQiS83+/vUsqvq+tEgpdlSZ+fn/25ImrknL9armOIBoeCwaFgcCgYHAoGh4LBoWBwKBgcCgaHgsGh\nYHAoGBwKBoeCwaFgcCgYHAoGh4LBoWBwKBgcCgaHgsGhYHAoGBwKBoeCwaFgcCgYHAoGR7S7cAY5\n5z/+nwe1jcEWDA4Fg+MuRN8N2ivCveCcs+pD3gpEx73glPokP03kESEEp0RhvbjrZEV/53nDnWCi\ni8sQXUoxDclnUQLtVeBScEo/Eo4eOEN5GwzR4LgXfNRS0UKpFe4Fp8RwPEIIwaSf0IIZpq8JI5hh\nuo8wgkkfFAxOeMF8D58TSjDfw3JCCSZyKBgcCgaHgsGhYHAoGBwKBoeCwaFgcCh4BeK0JwWDQ8En\nIMx9U/D/oO0qrFAwOBQMDgWDE0ow4jDGmlCCrUCuOOEFW/R2UXrQKQUSjNzKLAkjeK9VabQ09IoT\nRnBKfwpFCqOWuN0AfoT1kUpoFSdUCyZyKBicxwpG71xVHiv4KYTrZPXQ2lrROlgpAQt+Sgi+AjJE\nU+4PcIJ75SKG55SAQ3QrqGIrUIKvWi+6zD1gBJ/JfaLYSnjBbLXnhO5kUe41YVswQ3IbIVsw5bYT\nUjBpJ2SI3h75z1Z7TEjBKVFqKwzR4FAwOBQMDgWDQ8HgUDA4WTLcyDn/m1L6sssOEfC7lPLr6iKR\nYBIPhmhwKBgcCgaHgsGhYHAoGBwKBoeCwaFgcCgYHAoGh4LBoWBwKBgcCgaHgsGhYHBEOxter1dZ\nlsUoK0TC+/3+blmyIxK8LEv6/PzszxVRI+fctDaOIVpItCOaHiU4mhwN3OwuzDk/Ysfg7HO8TAQ/\nRVYPPc8l59z9TE1C9HaDtjaooXZbrrVYdy24/rc1Y7VSXF0vkbt3bYRj/GseNfKlKlgzYxppb6/d\nq0BXFaa1klzdW4Lm81MTrCF377eWlaaFlkqy/re939yJimCrgmmna/XgPYqtDAteF06r92zxwCx6\n9pr5tBp5DAve/rGq3kLPPBapPszR3rhWPi1HBerDpFpoaabrUMCqg3bUufISVq3yYTYO9oL3YZH1\npJDZVKXmO7mHqxZq2eGSjOWtn4+buWhtLMfiLWPns/vPrPSmgj2FQg0iludRnwufCAWDQ8HghBGM\n+onQmjCCSR8hBdcP4eSaUILXYiMOWVrRrLym4+BRGduC9q5nGvl9TePst56nQ81nsrSkjK5G1GgV\nR2lorBLpvdcV7qYq161FM1SNrjTRnFdvmavWupe7d3BL4e/oYLV8Px5Z3mqFeQseKfD2ofa80zU7\nZZHWYlWmvIOlHZ29zlVvRVmHey+rPbe/D/k9eM26AC0PRHMpTE1rZDnROr31773LTemGTtbsMHYk\nuQctses0Wq4buY+7TpaUs07XXm/c8l1skc5opXQ3TDqjZ0JBs9VpcrbIf4/elhxG8KgY7c6WxZqz\no/H/o0O0FOudjxpoVprHCU7JT5iegalg9AcZoXyPbMFPgoLBCSnYeyfJEyEFozDjy5jJEQ5XeN5P\nO5M6ZLMsy/Qd/lo1tmf/sccKcTUuH823iuDWDPSckGPV2mfu8OtBq0K6/Zp0NIesOdVYkaQpqaSS\nsmpOT66ZJnjkg33PuVuS+0rmlUcf/PY+1pFkiuDRVnf3ZnJtjqTuyR8ts+t10dt0pAX2WCmuVrJo\n59n0KEOtDtI6LekRCa1YjQBGI9coro8y3EuvpZZbtdoZ0UC7FauOg1OyabVbvIVdbTQlDwm26AF6\nfG9Gpkuw1fomyv1BrcEIe6VF8+abtClXQM75XUr55+o60dekj4+P0B2YJ8LPheBQMDgUDA4Fg0PB\n4DxWcJSFe6P57J7Jkt5YezJ/5lcly41rbjeA37EC4q7JkJZ1U9vrpWm7XnR3hKctm3uCpPm7qqza\nG9tcf/C3+HQoDctr9hbdSfNmOYtn1YqHO1l7i7e9tNxSbP6KyxGjJwpZoPZ3k2rhvHw0mJ0H7V65\n1nNUGyZ5knsXHsuuIni9/SLK+FIT7YqtmZ7KOziln9o7Q3KtUDMr09ED9xqaKyZbV3rC9dn162Wz\ne/e7C8vVo1oMr8k6y1BvbdTexmE1AzWa9oz9UWZTlT17iWa10N4tMGt68zh709tQC27dy9O6P2gG\nve9MrTA8+/ViPhctvdYCL1tF77h3mJPuRri7gt3JY78HP4WuddHEBfrrokk8KBgcCgaHgsGhYHAo\nGBwKBoeCwaFgcCgYHAoGh4LBoWBwKBgcCgaHgsGhYHAoGBwKBke6qvI7pfRlkREi5nfLRaJFdyQe\nDNHgUDA4FAwOBYNDweBQMDgUDA4Fg0PB4PwHkCHnyOTmldMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff521e6bad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def concat_images(X):\n",
    "    \"\"\"Concatenates a bunch of images into a big matrix for plotting purposes.\"\"\"\n",
    "    nc,h,w,_ = X.shape\n",
    "    X = X.reshape(nc,h,w)\n",
    "    n = np.ceil(np.sqrt(nc)).astype(\"int8\")\n",
    "    img = np.zeros((n*w,n*h))\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for example in range(nc):\n",
    "        img[x*w:(x+1)*w,y*h:(y+1)*h] = X[example]\n",
    "        y += 1\n",
    "        if y >= n:\n",
    "            y = 0\n",
    "            x += 1\n",
    "    return img\n",
    "\n",
    "\n",
    "def plot_oneshot_task(pairs):\n",
    "    \"\"\"Takes a one-shot task given to a siamese net and  \"\"\"\n",
    "    fig,(ax1,ax2) = plt.subplots(2)\n",
    "    ax1.matshow(pairs[0][0].reshape(105,105),cmap='gray')\n",
    "    img = concat_images(pairs[1])\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax2.matshow(img,cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "#example of a one-shot learning task\n",
    "pairs, targets = loader.make_oneshot_task(20,\"train\",\"Japanese_(katakana)\")\n",
    "plot_oneshot_task(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training loop\n",
    "evaluate_every = 500 # interval for evaluating on one-shot tasks\n",
    "loss_every=50 # interval for printing loss (iterations)\n",
    "batch_size = 32 \n",
    "n_iter = 900000 \n",
    "N_way = 20 # how many classes for testing one-shot tasks>\n",
    "n_val = 250 #how mahy one-shot tasks to validate on?\n",
    "best = 9999\n",
    "#siamese_net.load_weights(\"/home/soren/keras-oneshot/weights\")\n",
    "for i in range(1, n_iter):\n",
    "    (inputs,targets)=loader.get_batch(batch_size)\n",
    "    loss=siamese_net.train_on_batch(inputs,targets)\n",
    "    if i % evaluate_every == 0:\n",
    "        val_acc = loader.test_oneshot(siamese_net,N_way,n_val,verbose=True)\n",
    "        if val_acc >= best:\n",
    "            print(\"saving\")\n",
    "            siamese_net.save('/home/soren/keras-oneshot/weights')\n",
    "            best=val_acc\n",
    "\n",
    "    if i % loss_every == 0:\n",
    "        print(\"iteration {}, training loss: {:.2f},\".format(i,loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nearest_neighbour(pairs,targets):\n",
    "    \"\"\"Quick function to classify a pair of images using 1 nearest neighbour\"\"\"\n",
    "    L2_distances = np.zeros_like(targets)\n",
    "    for i in range(len(targets)):\n",
    "        L2_distances[i] = np.sum(np.sqrt(pairs[0][i]**2 - pairs[1][i]**2))\n",
    "    if np.argmin(L2_distances) == np.argmax(targets):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def test_nn_accuracy(N_ways,n_trials,loader):\n",
    "    print(\"Evaluating nearest neighbour on {} unique {} way one-shot learning tasks ...\".format(n_trials,N_ways))\n",
    "\n",
    "    n_right = 0\n",
    "    \n",
    "    for i in range(n_trials):\n",
    "        pairs,targets = loader.make_oneshot_task(N_ways,\"val\")\n",
    "        correct = nearest_neighbour(pairs,targets)\n",
    "        n_right+= correct\n",
    "    return 100.0 * n_right / n_trials\n",
    "\n",
    "#training loop\n",
    "siamese_net.load_weights(\"/home/soren/keras-oneshot/weights\")\n",
    "ways = np.arange(1,60,2)\n",
    "val_accs, train_accs,nn_accs = [],[],[]\n",
    "print(\"?\")\n",
    "trials = 450\n",
    "for N in ways:\n",
    "    val_accs.append(loader.test_oneshot(siamese_net,N,trials,\"val\",verbose=True))\n",
    "    train_accs.append(loader.test_oneshot(siamese_net,N,trials,\"train\",verbose=True))\n",
    "    nn_accs.append(test_nn_accuracy(N,trials,loader))\n",
    "import seaborn as sns\n",
    "plt.plot(ways,val_accs,\"m\")\n",
    "plt.plot(ways,train_accs,\"y\")\n",
    "plt.plot(ways,nn_accs,\"c\")\n",
    "\n",
    "plt.plot(ways,100.0/ways,\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "ax.plot(ways,val_accs,\"m\",label=\"Siamese(val set)\")\n",
    "ax.plot(ways,train_accs,\"y\",label=\"Siamese(train set)\")\n",
    "plt.plot(ways,nn_accs,label=\"Nearest neighbour\")\n",
    "\n",
    "ax.plot(ways,100.0/ways,\"g\",label=\"Random guessing\")\n",
    "plt.xlabel(\"Number of possible classes in one-shot tasks\")\n",
    "plt.ylabel(\"% Accuracy\")\n",
    "plt.title(\"Omiglot One-Shot Learning Performance of a Siamese Network\")\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "inputs,targets = loader.make_oneshot_task(20,\"val\")\n",
    "plt.show()\n",
    "\n",
    "print(inputs[0].shape)\n",
    "plot_oneshot_task(inputs)\n",
    "p=siamese_net.predict(inputs)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "a=test_nn_accuracy(3,500,loader)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
